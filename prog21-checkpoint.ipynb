{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79dd069",
   "metadata": {},
   "source": [
    "## 講義（後期，第１５回）ノート　＜テキストマイニング（ワードクラウド実装）＞<br>本講義の単元に関する提出課題はありません．ただし，後期の締めくくりとして，自由課題を課しています．詳しくは，最下部を参照．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1456b",
   "metadata": {},
   "source": [
    "## テキストマイニング<br><br>　大量の文章データ（テキストデータ）から有益な情報を取り出すことをテキストマイニングという．本講義では，発展編として，テキストデータ内の頻出語を頻度に比例する大きさで雲（cloud）のように並べたワードクラウドと呼ばれる図を生成し，スピーチ内容の主題を類推することを考えよう．<br><br>Step 1．wordcloud のインストール<br><br>　wordcloud は，頻出語を頻度に比例する大きさで雲（cloud）のように並べた図を生成するライブラリである．はじめに，以下の Code セルを実行し，SpeechRecognition をインストールする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac613c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85068733",
   "metadata": {},
   "source": [
    "## インストールがうまく行えた場合は，下記のような文章が表示される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebaba9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.rs.tus.ac.jp/yenatsu/idm2021prog/wordcloud_install.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://www.rs.tus.ac.jp/yenatsu/idm2021prog/wordcloud_install.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e33233",
   "metadata": {},
   "source": [
    "## 注意．Anaconda を使って python をインストールした環境であったり，上記のプログラムを実行してもインストールが行われない場合は，\"pip\" の部分を \"conda\" として，\"conda install wordcloud\" という文を Code セル内に入力したものを実行しよう．<br><br>【Windows ユーザー向け】<br><br>Step 2．txt データのアップロード<br><br>　前回用いた英語の音声データ：<br><br>dream.wav<br><br>録音内容＜人種差別撤廃活動を率いたキング牧師（Martin Luther King, Jr.）の原稿＞：<br>　I say to you today, my friends, so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American Dream. I have a dream that one day this nation will rise up, and live out the true meaning of its creed; “We hold these truths to be self-evident, that all men are created equal.” I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave-owners, will be able to sit down together at the table of brotherhood.<br><br>を文字に起こした txt データに現れる英単語の頻度を，以下の Code セルを実行することで，ワードクラウドにより可視化しよう．LETUS にアップされている <span style=\"color: red; \">dream_sjis.txt</span> を各自の PC に保存し，Jupyter Notebook のファイル一覧に本講義ノート prog29.ipynb と dream_sjis.txt が一緒に表示されるように，txt ファイルを Jupyter Notebook にアップロードしよう．<br><br>Step 3．Word Cloud の生成<br><br>　以下の Code セルを実行しよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ad1e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2ba87d86100>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "text_file = open(\"dream_sjis.txt\")\n",
    "bindata = text_file.read()\n",
    "txt = bindata\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "    width=800,height=600).generate(txt)\n",
    "\n",
    "# 画像ファイルの生成\n",
    "wordcloud.to_file(\"./wordcloud_dream.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59c8ad",
   "metadata": {},
   "source": [
    "## 【Mac ユーザー向け】<br><br>Step 2．txt データのアップロード<br><br>　前回用いた英語の音声データ：<br><br>dream.wav<br><br>録音内容＜人種差別撤廃活動を率いたキング牧師（Martin Luther King, Jr.）の原稿＞：<br>　I say to you today, my friends, so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American Dream. I have a dream that one day this nation will rise up, and live out the true meaning of its creed; “We hold these truths to be self-evident, that all men are created equal.” I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave-owners, will be able to sit down together at the table of brotherhood.<br><br>を文字に起こした txt データに現れる英単語の頻度を，以下の Code セルを実行することで，ワードクラウドにより可視化しよう．LETUS にアップされている <span style=\"color: red; \">dream_utf.txt</span> を各自の PC に保存し，Jupyter Notebook のファイル一覧に本講義ノート prog29.ipynb と dream_utf.txt が一緒に表示されるように，txt ファイルを Jupyter Notebook にアップロードしよう．<br><br>Step 3．Word Cloud の生成<br><br>　ワードクラウド用のフォントを指定するための命令文も添えた以下の Code セルを実行しよう．実行後，“OSError: cannot open resource\" といったエラーが出たときは，下記の URL：<br>https://qiita.com/Afo_guard_enthusiast/items/60e21acc6259a58e7ff0<br>に沿って，各自の PC に元々入っている別のフォントを使うと良い．”System/Library/Fonts” の配下にフォントファイルがあるので，HelveticaNeue.ttc 以外のもので希望のフォントファイルがある場合も含めて，適宜別のフォントを選ぼう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa437c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# 画像ファイルの生成\n",
    "text_file = open(\"dream_utf.txt\")\n",
    "bindata = text_file.read()\n",
    "txt = bindata\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "    font_path=\"System/Library/Fonts/HelveticaNeue.ttc\",\n",
    "    width=800,height=600).generate(txt)\n",
    "\n",
    "# 画像ファイルの生成\n",
    "wordcloud.to_file(\"./wordcloud_dream.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f36e99",
   "metadata": {},
   "source": [
    "## 上記のプログラムを実行後，ワードクラウドの画像ファイル wordcloud_dream.png が生成される．Jupyter Notebook のファイル一覧に wordcloud_dream.png が表示されたことを確認し，この画像をダウンロードすることで，閲覧してみよう．実際は，wordcloud_dream.png を開くと，次のような画像が表示される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5281fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.rs.tus.ac.jp/yenatsu/idm2021prog/wordcloud_dream.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://www.rs.tus.ac.jp/yenatsu/idm2021prog/wordcloud_dream.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c9abf",
   "metadata": {},
   "source": [
    "## 上のワードクラウドから，difficulties, slave, nation, American といった語が txt データ内のスピーチ原稿に含まれていることが分かる．この結果から，スピーチ内容がアメリカでの人種差別撤廃活動に沿ったものであるとの類推に対して，さらに違和感はなくなる．なお，主語 I（わたし），冠詞 the, a，前置詞 of, to や接続詞 and などのテーマによらず頻出する単語は，クラウドデータからはあらかじめ除かれる．そのため，頻出単語の中でもテーマへの関連度が高いキーワードを見れることが，クラウドデータを使うことのメリットと言える．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3bbeb",
   "metadata": {},
   "source": [
    "## <span style=\"color: red; \">提出課題（任意）＜締切：１月２１日（土）２３：５９＞</span><br><br>自由課題として，後期で学んだ単元のいずれかについて各自で調べたことをまとめて，メールで提出せよ．テーマは自由で良いが，<span style=\"color: blue; \">まとめた内容の参考文献（第２１回参照）や内容を特徴付けるタイトルを冒頭に書く</span>こと．提出ファイルの拡張子は ipynb に限らず，doc, pdf や jpg といった文書形式や画像を含めたものでも構わない（提出ファイルの数も限定しない）．ファイル内に<span style=\"color: blue; \">自身の考えや論述が添えられていないものは，加点の対象とならない</span>ため，注意しよう．今回の課題では，<span style=\"color: blue; \">時間をおいて提出状況を見てから受講者の答案に目を通す</span>ので，満点解答の提出日時に関する情報開示は特に行いません．そのため，締切まで<span style=\"color: blue; \">じっくり時間をかけての取り組みを推奨します</span>．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
