{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7dd2259",
   "metadata": {},
   "source": [
    "## 講義（後期，第１４回）ノート　＜テキストマイニング（音声データの文字起こし）＞<br>提出課題はありません．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a6f91",
   "metadata": {},
   "source": [
    "## 【再掲】7.1 matplotlib（p.86～）<br><br>Python では，グラフ描画が可能である．次の Code セルを実行し，グラフを表示する際に使われるパッケージ（複数のモジュールをまとめて扱えるようにしたもの）の一つとして，matplotlib を使う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34689f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afab4d0",
   "metadata": {},
   "source": [
    "## テキストマイニング<br><br>　大量の文章データ（テキストデータ）から有益な情報を取り出すことをテキストマイニングという．本講義では，基本編として，スピーチ音源から日本語や英語を抽出し，スピーチ内の頻出単語を列挙することで内容の主題を類推することを考えよう．<br><br>Step 1．SpeechRecognition のインストール<br><br>　SpeechRecognition は，google と連携して日本語や英語などの音声認識をリアルタイムで実施できるライブラリである．はじめに，以下の Code セルを実行し，SpeechRecognition をインストールする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6108d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744001b",
   "metadata": {},
   "source": [
    "## インストールがうまく行えた場合は，下記のような文章が表示される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48df877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.rs.tus.ac.jp/yenatsu/idm2021prog/sprec_install.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://www.rs.tus.ac.jp/yenatsu/idm2021prog/sprec_install.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8a8af",
   "metadata": {},
   "source": [
    "## 注意．Anaconda を使って python をインストールした環境であったり，上記のプログラムを実行してもインストールが行われない場合は，\"pip\" の部分を \"conda\" として，\"conda install SpeechRecognition\" という文を Code セル内に入力したものを実行しよう．<br><br>Step 2．Jupyter Notebook 上での音声データのアップロード<br><br>　音声データの例として，下記２つの wav ファイルを使う．<br><br>（１）comment.wav<br><br>録音内容：<br>　皆さん、こんにちは．プログラミングの授業も残り２回となりましたが、興味のある単元は見つかったでしょうか？メールマナーにはだいぶ慣れていて、課題の提出状況も全体的に良かったです．皆さんの引き続きの頑張りも大いに期待しています．<br><br>（２）dream.wav<br><br>録音内容＜人種差別撤廃活動を率いたキング牧師（Martin Luther King, Jr.）の原稿＞：<br>　I say to you today, my friends, so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American Dream. I have a dream that one day this nation will rise up, and live out the true meaning of its creed; “We hold these truths to be self-evident, that all men are created equal.” I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave-owners, will be able to sit down together at the table of brotherhood.<br><br>LETUS にアップされている上記２つの wav ファイルを各自の PC に保存し，Jupyter Notebook のファイル一覧に本講義ノート prog27.ipynb と２つの wav ファイルのすべてが一緒に表示されるように，２つの wav ファイルを Jupyter Notebook にアップロードしよう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016ddcd",
   "metadata": {},
   "source": [
    "## Step 3．SpeechRecognition を使った音声データの文字起こし<br><br>　以下の Code セルを実行し，Step 2 でアップした２つの音源内の文字を起こす．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90825ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'皆さんこんにちは プログラミングの授業も残り2回となりましたが 興味のある単元は見つかったでしょうか メールマナーにはだいぶ慣れて課題の提出状況も全体的に良かったです 皆さんの引き続きの頑張りも大いに期待しています'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    " \n",
    "### 音声収録 ###\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"comment.wav\") as wavdata:\n",
    "    voice = r.record(wavdata)\n",
    "\n",
    "### 収録データの日本語による文字起こし（音声認識にグーグルのサービスを利用）###\n",
    "jtext = r.recognize_google(voice, language='ja-JP')\n",
    "\n",
    "jtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f707d3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I say to you today my friends so even though we Face the difficulties of today and tomorrow I still have a dream it is a dream deeply rooted in the American dream I have a dream that one day this nation will rise up and live out the true meaning of its Creed we hold these truths to be self-evident that all men are created equal I have a dream that one day on the Red Hills of Georgia the sounds of Homer slaves and the sons of former slaves owners will be able to sit down together at the table of Brotherhood'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "### 音声収録 ###\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"dream.wav\") as wavdata:\n",
    "    voice = r.record(wavdata)\n",
    "\n",
    "### 収録データの英語による文字起こし（音声認識にグーグルのサービスを利用）###\n",
    "etext = r.recognize_google(voice, language='en-US')\n",
    "\n",
    "etext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10549df0",
   "metadata": {},
   "source": [
    "## 上記のプログラムを実行することで，音声データの収録内容が jtest と etext のそれぞれに格納された（PC によってはボイスレコーダー機能がついていて，自身の声が録音された音声データを作成できる．可能であれば，ぜひ各自の PC でも録音を試してみよう）．ただし，SpeechRecognition で扱える音声データの拡張子は wav のみであるため，PC や携帯電話での録音によって作成された音声データの拡張子が .amr, .m4a, .mp3 などの場合は，以下のサイト：<br><br>https://convertio.co/ja/audio-converter/<br><br>を使って，オンライン上で wav 形式にファイルをコンバートしよう．また，録音ボイスが小さかったり，不明瞭な場合は，起こされた単語が誤っていたり，言語の拾い上げが途中で中止されてしまう点にも注意しよう．<br>　以降は，簡単のために，単語を切り分けやすい英語の音声データ dream.wav を使って，頻出単語の列挙を行おう．<br><br>Step 4．頻出単語の列挙<br><br>　はじめに，関数 split() を使って，空白によって区切られた単語のそれぞれを１つの文字列の組として，a に格納する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35eea87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'say',\n",
       " 'to',\n",
       " 'you',\n",
       " 'today',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'so',\n",
       " 'even',\n",
       " 'though',\n",
       " 'we',\n",
       " 'Face',\n",
       " 'the',\n",
       " 'difficulties',\n",
       " 'of',\n",
       " 'today',\n",
       " 'and',\n",
       " 'tomorrow',\n",
       " 'I',\n",
       " 'still',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'deeply',\n",
       " 'rooted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'American',\n",
       " 'dream',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'that',\n",
       " 'one',\n",
       " 'day',\n",
       " 'this',\n",
       " 'nation',\n",
       " 'will',\n",
       " 'rise',\n",
       " 'up',\n",
       " 'and',\n",
       " 'live',\n",
       " 'out',\n",
       " 'the',\n",
       " 'true',\n",
       " 'meaning',\n",
       " 'of',\n",
       " 'its',\n",
       " 'Creed',\n",
       " 'we',\n",
       " 'hold',\n",
       " 'these',\n",
       " 'truths',\n",
       " 'to',\n",
       " 'be',\n",
       " 'self-evident',\n",
       " 'that',\n",
       " 'all',\n",
       " 'men',\n",
       " 'are',\n",
       " 'created',\n",
       " 'equal',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'that',\n",
       " 'one',\n",
       " 'day',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Red',\n",
       " 'Hills',\n",
       " 'of',\n",
       " 'Georgia',\n",
       " 'the',\n",
       " 'sounds',\n",
       " 'of',\n",
       " 'Homer',\n",
       " 'slaves',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sons',\n",
       " 'of',\n",
       " 'former',\n",
       " 'slaves',\n",
       " 'owners',\n",
       " 'will',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'down',\n",
       " 'together',\n",
       " 'at',\n",
       " 'the',\n",
       " 'table',\n",
       " 'of',\n",
       " 'Brotherhood']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=etext.split()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbfae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etext の５語目に格納されている単語\n",
    "a[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854a99d",
   "metadata": {},
   "source": [
    "## 次に，関数 Counter() を使って，キーとなる単語と値となる単語の出現回数が格納された辞書データを作成する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9480dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 7, 'of': 6, 'dream': 5, 'I': 4, 'a': 4, 'to': 3, 'and': 3, 'have': 3, 'that': 3, 'today': 2, 'we': 2, 'one': 2, 'day': 2, 'will': 2, 'be': 2, 'slaves': 2, 'say': 1, 'you': 1, 'my': 1, 'friends': 1, 'so': 1, 'even': 1, 'though': 1, 'Face': 1, 'difficulties': 1, 'tomorrow': 1, 'still': 1, 'it': 1, 'is': 1, 'deeply': 1, 'rooted': 1, 'in': 1, 'American': 1, 'this': 1, 'nation': 1, 'rise': 1, 'up': 1, 'live': 1, 'out': 1, 'true': 1, 'meaning': 1, 'its': 1, 'Creed': 1, 'hold': 1, 'these': 1, 'truths': 1, 'self-evident': 1, 'all': 1, 'men': 1, 'are': 1, 'created': 1, 'equal': 1, 'on': 1, 'Red': 1, 'Hills': 1, 'Georgia': 1, 'sounds': 1, 'Homer': 1, 'sons': 1, 'former': 1, 'owners': 1, 'able': 1, 'sit': 1, 'down': 1, 'together': 1, 'at': 1, 'table': 1, 'Brotherhood': 1})\n"
     ]
    }
   ],
   "source": [
    "import collections # Counter() を使うためのライブラリ collections をインポート\n",
    "\n",
    "d = collections.Counter(a)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eead17",
   "metadata": {},
   "source": [
    "## 辞書データ d に対して関数 most_common() を使って，単語の出現回数が上から２０番目までで多い順に並べられた要素と出現回数の組から成るリストを作成する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63397636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7),\n",
       " ('of', 6),\n",
       " ('dream', 5),\n",
       " ('I', 4),\n",
       " ('a', 4),\n",
       " ('to', 3),\n",
       " ('and', 3),\n",
       " ('have', 3),\n",
       " ('that', 3),\n",
       " ('today', 2),\n",
       " ('we', 2),\n",
       " ('one', 2),\n",
       " ('day', 2),\n",
       " ('will', 2),\n",
       " ('be', 2),\n",
       " ('slaves', 2),\n",
       " ('say', 1),\n",
       " ('you', 1),\n",
       " ('my', 1),\n",
       " ('friends', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = d.most_common(20)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14af114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dream'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d811579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58536503",
   "metadata": {},
   "source": [
    "## 最後に，単語の出現回数に関する棒グラフを描画する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4daf2720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(7):\n",
    "    x.append(c[i][0]) # 横軸の x 座標として，単語の出現回数を表すリストを作成する\n",
    "    y.append(c[i][1]) # 縦軸の y 座標として，単語そのものを表すリストを作成する\n",
    "\n",
    "plt.barh(x, y, height = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44346901",
   "metadata": {},
   "source": [
    "## 主語 I（わたし），冠詞 the, a，前置詞 of, to や接続詞 and などのテーマによらず頻出する単語を除くと，dream という語がスピーチの中に最も多く現れる．このことから，dream.wav に収録されてたスピーチは，将来のこと（実際は将来への希望）が主たる内容であると類推される．<br><br>　次回は発展編として，テキストデータ内の頻出語を，頻度に比例する大きさで雲（cloud）のように並べたワードクラウドと呼ばれる図を生成する．このワードクラウドによる手続きを通して，スピーチ内容の主題をより詳しく類推しよう．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
